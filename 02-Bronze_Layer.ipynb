{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdb756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks Notebook\n",
    "# ===================================\n",
    "# 02_Bronze_Layer\n",
    "# ===================================\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ブロンズレイヤー構築開始\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ===================================\n",
    "# 1. 商品マスタ（JSON）の取り込み\n",
    "# ===================================\n",
    "\n",
    "print(\"\\n[1/3] 商品マスタデータ取り込み中...\")\n",
    "\n",
    "# JSONスキーマ定義（オプション：パフォーマンス向上のため）\n",
    "items_schema = StructType([\n",
    "    StructField(\"item_id\", StringType(), True),\n",
    "    StructField(\"item_name\", StringType(), True),\n",
    "    StructField(\"category_l1\", StringType(), True),\n",
    "    StructField(\"category_l2\", StringType(), True),\n",
    "    StructField(\"category_l3\", StringType(), True),\n",
    "    StructField(\"brand\", StringType(), True),\n",
    "    StructField(\"price\", IntegerType(), True),\n",
    "    StructField(\"cost\", IntegerType(), True),\n",
    "    StructField(\"color\", StringType(), True),\n",
    "    StructField(\"size\", StringType(), True),\n",
    "    StructField(\"season\", StringType(), True),\n",
    "    StructField(\"launch_date\", StringType(), True),\n",
    "    StructField(\"is_active\", BooleanType(), True)\n",
    "])\n",
    "\n",
    "# JSONファイル読み込み\n",
    "items_raw_df = spark.read \\\n",
    "    .schema(items_schema) \\\n",
    "    .json(\"/FileStore/sample_data/items/*.json\")\n",
    "\n",
    "# メタデータ追加\n",
    "items_bronze_df = items_raw_df \\\n",
    "    .withColumn(\"ingestion_timestamp\", current_timestamp()) \\\n",
    "    .withColumn(\"source_system\", lit(\"product_master_db\")) \\\n",
    "    .withColumn(\"file_name\", input_file_name())\n",
    "\n",
    "# Deltaテーブルとして保存（ブロンズレイヤー）\n",
    "items_bronze_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .save(f\"{BRONZE_PATH}/items\")\n",
    "\n",
    "# テーブル登録\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bronze_items\n",
    "    USING DELTA\n",
    "    LOCATION '{BRONZE_PATH}/items'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"✓ 商品マスタ取り込み完了: {items_bronze_df.count():,}件\")\n",
    "\n",
    "# ===================================\n",
    "# 2. 広告データ（CSV）の取り込み\n",
    "# ===================================\n",
    "\n",
    "print(\"\\n[2/3] 広告データ取り込み中...\")\n",
    "\n",
    "# CSVスキーマ定義\n",
    "ads_schema = StructType([\n",
    "    StructField(\"campaign_id\", StringType(), True),\n",
    "    StructField(\"campaign_name\", StringType(), True),\n",
    "    StructField(\"ad_id\", StringType(), True),\n",
    "    StructField(\"ad_platform\", StringType(), True),\n",
    "    StructField(\"ad_format\", StringType(), True),\n",
    "    StructField(\"target_url\", StringType(), True),\n",
    "    StructField(\"impressions\", IntegerType(), True),\n",
    "    StructField(\"clicks\", IntegerType(), True),\n",
    "    StructField(\"cost\", DoubleType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"utm_source\", StringType(), True),\n",
    "    StructField(\"utm_medium\", StringType(), True),\n",
    "    StructField(\"utm_campaign\", StringType(), True),\n",
    "    StructField(\"target_category\", StringType(), True)\n",
    "])\n",
    "\n",
    "# CSVファイル読み込み\n",
    "ads_raw_df = spark.read \\\n",
    "    .schema(ads_schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"/FileStore/sample_data/digital_ads/*-ads.csv\")\n",
    "\n",
    "# メタデータ追加\n",
    "ads_bronze_df = ads_raw_df \\\n",
    "    .withColumn(\"ingestion_timestamp\", current_timestamp()) \\\n",
    "    .withColumn(\"source_system\", lit(\"google_ads_api\")) \\\n",
    "    .withColumn(\"file_name\", input_file_name())\n",
    "\n",
    "# Deltaテーブルとして保存\n",
    "ads_bronze_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .save(f\"{BRONZE_PATH}/digital_ads\")\n",
    "\n",
    "# テーブル登録\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bronze_digital_ads\n",
    "    USING DELTA\n",
    "    LOCATION '{BRONZE_PATH}/digital_ads'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"✓ 広告データ取り込み完了: {ads_bronze_df.count():,}件\")\n",
    "\n",
    "# ===================================\n",
    "# 3. トランザクションデータ（CSV）の取り込み\n",
    "# ===================================\n",
    "\n",
    "print(\"\\n[3/3] トランザクションデータ取り込み中...\")\n",
    "\n",
    "# CSVスキーマ定義\n",
    "transactions_schema = StructType([\n",
    "    StructField(\"transaction_id\", StringType(), True),\n",
    "    StructField(\"transaction_timestamp\", StringType(), True),\n",
    "    StructField(\"item_id\", StringType(), True),\n",
    "    StructField(\"user_email\", StringType(), True),\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True),\n",
    "    StructField(\"price\", IntegerType(), True),\n",
    "    StructField(\"referrer_url\", StringType(), True),\n",
    "    StructField(\"landing_page_url\", StringType(), True),\n",
    "    StructField(\"utm_source\", StringType(), True),\n",
    "    StructField(\"utm_medium\", StringType(), True),\n",
    "    StructField(\"utm_campaign\", StringType(), True),\n",
    "    StructField(\"device_type\", StringType(), True),\n",
    "    StructField(\"session_id\", StringType(), True),\n",
    "    StructField(\"conversion_time_minutes\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# CSVファイル読み込み\n",
    "transactions_raw_df = spark.read \\\n",
    "    .schema(transactions_schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"/FileStore/sample_data/transactions/*-transactions.csv\")\n",
    "\n",
    "# メタデータ追加\n",
    "transactions_bronze_df = transactions_raw_df \\\n",
    "    .withColumn(\"ingestion_timestamp\", current_timestamp()) \\\n",
    "    .withColumn(\"source_system\", lit(\"ec_site_db\")) \\\n",
    "    .withColumn(\"file_name\", input_file_name())\n",
    "\n",
    "# Deltaテーブルとして保存\n",
    "transactions_bronze_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .save(f\"{BRONZE_PATH}/transactions\")\n",
    "\n",
    "# テーブル登録\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bronze_transactions\n",
    "    USING DELTA\n",
    "    LOCATION '{BRONZE_PATH}/transactions'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"✓ トランザクションデータ取り込み完了: {transactions_bronze_df.count():,}件\")\n",
    "\n",
    "# ===================================\n",
    "# ブロンズレイヤー完成確認\n",
    "# ===================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ブロンズレイヤー構築完了\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# テーブル一覧表示\n",
    "print(\"\\n【作成されたテーブル】\")\n",
    "display(spark.sql(\"SHOW TABLES IN ad_analytics\"))\n",
    "\n",
    "# サンプルデータ表示\n",
    "print(\"\\n【ブロンズ: 商品マスタ（先頭5件）】\")\n",
    "display(spark.table(\"bronze_items\").limit(5))\n",
    "\n",
    "print(\"\\n【ブロンズ: 広告データ（先頭5件）】\")\n",
    "display(spark.table(\"bronze_digital_ads\").limit(5))\n",
    "\n",
    "print(\"\\n【ブロンズ: トランザクション（先頭5件）】\")\n",
    "display(spark.table(\"bronze_transactions\").limit(5))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
