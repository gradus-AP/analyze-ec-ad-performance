{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51d3e0c",
   "metadata": {},
   "source": [
    "## データのアップロード方法\n",
    "\n",
    "1. Databricks UIの左メニューから「Data」を選択\n",
    "2. 「Upload File」をクリック\n",
    "3. 生成した sample_data フォルダ内のファイルをアップロード<br>または、AWS S3 / Azure Blob Storage / ADLS Gen2 からマウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878eed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks Notebook\n",
    "# ===================================\n",
    "# Setup: データのアップロードと確認\n",
    "# ===================================\n",
    "\n",
    "# データのアップロード先確認\n",
    "dbutils.fs.ls(\"/FileStore/\")\n",
    "\n",
    "# サンプルデータをアップロード後、以下のパスに配置されていると仮定\n",
    "# /FileStore/sample_data/items/\n",
    "# /FileStore/sample_data/digital_ads/\n",
    "# /FileStore/sample_data/transactions/\n",
    "# /FileStore/sample_data/ad_clicks/\n",
    "\n",
    "# データの確認\n",
    "print(\"=== Items ===\")\n",
    "display(dbutils.fs.ls(\"/FileStore/sample_data/items/\"))\n",
    "\n",
    "print(\"\\n=== Digital Ads ===\")\n",
    "display(dbutils.fs.ls(\"/FileStore/sample_data/digital_ads/\"))\n",
    "\n",
    "print(\"\\n=== Transactions ===\")\n",
    "display(dbutils.fs.ls(\"/FileStore/sample_data/transactions/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d1eca",
   "metadata": {},
   "source": [
    "## データベースとストレージの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks Notebook\n",
    "# ===================================\n",
    "# 01_Setup_Database\n",
    "# ===================================\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# データベース名\n",
    "DATABASE_NAME = \"ad_analytics\"\n",
    "\n",
    "# Deltaテーブル保存先（DBFSパス）\n",
    "BASE_PATH = \"/mnt/lakehouse\"  # または \"/user/hive/warehouse/ad_analytics.db\"\n",
    "\n",
    "# ブロンズ、シルバー、ゴールドのパス\n",
    "BRONZE_PATH = f\"{BASE_PATH}/bronze\"\n",
    "SILVER_PATH = f\"{BASE_PATH}/silver\"\n",
    "GOLD_PATH = f\"{BASE_PATH}/gold\"\n",
    "\n",
    "# データベース作成\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {DATABASE_NAME}\")\n",
    "spark.sql(f\"USE {DATABASE_NAME}\")\n",
    "\n",
    "print(f\"✓ データベース '{DATABASE_NAME}' を作成しました\")\n",
    "print(f\"✓ 保存先: {BASE_PATH}\")\n",
    "\n",
    "# ディレクトリ構造確認\n",
    "print(\"\\n【ディレクトリ構造】\")\n",
    "print(f\"Bronze: {BRONZE_PATH}\")\n",
    "print(f\"Silver: {SILVER_PATH}\")\n",
    "print(f\"Gold: {GOLD_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
